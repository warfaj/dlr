# 3. Classification where input is a vector, output is categorical (softmax & negative log likelihood loss).

import numpy as np
import torch
import matplotlib.pyplot as plt

DATASET_SIZE = 1000000

# Data is 5 dimensional vec; target is 3 categories 
data = np.random.random((DATASET_SIZE,5))
#shuffle data (unnecssary since random but good practice)
np.random.shuffle(data)
data = torch.tensor(data,  dtype=torch.float64)

# A learnable target function for categorical data generated by Claude
def generate_targets(data, noise_level=0.1):
    """
    Generate targets using a learnable function:
    - Class 0: When sum of first two features > 1.0
    - Class 1: When product of features 3 and 4 > 0.25
    - Class 2: Otherwise
    
    Adds some noise to make it more challenging
    """
    targets = np.zeros(data.shape[0], dtype=np.int64)
    
    # Rule for class 0
    mask_class0 = data[:, 0] + data[:, 1] > 1.0
    
    # Rule for class 1
    mask_class1 = data[:, 3] * data[:, 4] > 0.25
    
    # Set class 0 (has priority over class 1)
    targets[mask_class0] = 0
    
    # Set class 1 where class 0 doesn't apply
    targets[~mask_class0 & mask_class1] = 1
    
    # Class 2 is the default (where neither class 0 nor class 1 applies)
    targets[~mask_class0 & ~mask_class1] = 2
    
    # Add noise by randomly flipping some labels
    if noise_level > 0:
        noise_mask = np.random.random(data.shape[0]) < noise_level
        num_flipped = noise_mask.sum()
        
        # For each flipped label, randomly choose one of the other two classes
        random_classes = np.random.randint(1, 3, size=num_flipped)
        targets[noise_mask] = (targets[noise_mask] + random_classes) % 3
    
    return torch.tensor(targets, dtype=torch.int64)

# Generate targets using our learnable function
targets = generate_targets(data)

# Print class distribution
class_counts = np.bincount(targets.numpy())
print(f"Class distribution: {class_counts}")
print(f"Class percentages: {class_counts / DATASET_SIZE * 100}%")

# Initialize weights and hyperparameters
learning_rate = 0.01
iters = 0
max_iters = 100000
batch_size = 100
weights = torch.rand((5,5), requires_grad=True, dtype=torch.float64)
b = torch.rand(5, requires_grad=True, dtype=torch.float64 )
losses = []


# loss is equivalent to the negative log probability (higher likelihoods for correct class are smaller)
def loss(target, output):
    log_soft_max = torch.log_softmax(output, 1, dtype=torch.float64)
    return -log_soft_max[torch.arange(log_soft_max.size(0)), target].mean()


def forward(x, w, b):
    assert x.shape[1] == w.shape[0] and x.shape[1] == w.shape[1], "x and w aren't compatible sizes"
    assert w.shape[0] == b.shape[0], "w and b are not the correct size"
    return x @ w + b


# SGD gradient descent on vector linear reg
for i in range(0, data.shape[0], batch_size):
    if iters >= max_iters:
        break
    x = data[i:i+batch_size]
    t = targets[i:i+batch_size]
    loss_val = loss(t, forward(x,weights,b))
    loss_val.backward()
    # detach so weight update is not part of computational graph
    with torch.no_grad():
        weights -= learning_rate * weights.grad
        b -= learning_rate * b.grad
        weights.grad.zero_()
        b.grad.zero_()
    losses.append(loss_val.item())
    iters += 1
        

print(weights, b)

# Plot loss curve
plt.figure(figsize=(15, 5))
plt.subplot(1, 2, 1)
plt.plot(losses)
plt.title('Training Loss Over Time')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.xscale('log')
plt.yscale('log')
plt.grid(True)
plt.savefig("graph.png", bbox_inches="tight")
plt.show()